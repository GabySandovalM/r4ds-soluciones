[
["modelos-conceptos-basicos.html", "18 Modelos: conceptos básicos 18.1 Paquetes necesarios 18.2 Un modelo simple 18.3 Visualizando modelos 18.4 Fórmulas y familias de modelos", " 18 Modelos: conceptos básicos 18.1 Paquetes necesarios library(tibble) library(ggplot2) library(purrr) library(modelr) library(tidyr) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(stringr) library(datos) 18.2 Un modelo simple 18.2.1 Ejercicios Una desventaja del modelo lineal es ser sensible a valores inusuales debido a que la distancia incorpora un término al cuadrado. Ajusta un modelo a los datos simulados que se presentan a continuación y visualiza los resultados. Corre el modelo varias veces para generar diferentes conjuntos de datos simulados. ¿Qué puedes observar respecto del modelo? sim1a &lt;- tibble( x = rep(1:10, each = 3), y = x * 1.5 + 6 + rt(length(x), df = 2) ) Solución Se puede correr una vez y graficar los resultados. ggplot(sim1a, aes(x = x, y = y)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) Para sistematizarlo, se pueden generar varias simulaciones y luego graficar las líneas. simt &lt;- function(i) { tibble( x = rep(1:10, each = 3), y = x * 1.5 + 6 + rt(length(x), df = 2), .id = i ) } sims &lt;- map_df(1:12, simt) ggplot(sims, aes(x = x, y = y)) + geom_point() + geom_smooth(method = &quot;lm&quot;, colour = &quot;red&quot;) + facet_wrap(~.id, ncol = 4) El ejercicio usa la función rt() la cual entrega un muestreo a partir de una distribución t-Student, la cual tiene colas más largas que la distribución normal (rnorm()), por lo tanto asigna una mayor probabilidad a los valores fuera del centro de la distribución. ¿Qué ocurre si usamos una distribución normal? sim_norm &lt;- function(i) { tibble( x = rep(1:10, each = 3), y = x * 1.5 + 6 + rnorm(length(x)), .id = i ) } simdf_norm &lt;- map_df(1:12, sim_norm) ggplot(simdf_norm, aes(x = x, y = y)) + geom_point() + geom_smooth(method = &quot;lm&quot;, colour = &quot;red&quot;) + facet_wrap(~.id, ncol = 4) Al usar distribución normal no hay tantos valores extremos y las pendientes son más similares. Para el caso de la distribución normal con media cero y desviación estándar uno, la probabilidad de que un valor sea mayor a dos se obtiene con pnorm(). pnorm(2, lower.tail = FALSE) ## [1] 0.02275013 Para el caso de la distribución t-Student con dos grados de libertad, la probabilidad es más del triple del caso anterior y se obtiene con pt(). pt(2, df = 2, lower.tail = FALSE) ## [1] 0.09175171 Podemos concluir que el modelo es sensible a valores extremos y en general a la distribución que siguen los datos. Una forma de obtener un modelo lineal más robusto es usar una métrica distinta para la distancia. Por ejemplo, en lugar de la raíz de la distancia media cuadrática (del inglés root-mean-squared distance) se podría usar la media de la distancia absoluta: medir_distancia &lt;- function(modelo, datos) { diferencia &lt;- datos$y - modelo1(modelo, datos) mean(abs(diferencia)) } Usa optim() para ajustar este modelo a los datos simulados anteriormente y compara el resultado con el modelo lineal. Solución Usando los datos sim1a y optim() podemos encontrar los parámetros que minimizan la desviación absoluta. Definiremos la función modelo1() tal como se hizo en el libro. modelo1 &lt;- function(a, datos) { a[1] + datos$x * a[2] } beta &lt;- optim(c(0, 0), medir_distancia, datos = sim1a) beta$par ## [1] 6.020399 1.467457 Los resultados del modelo lineal son los mismos que se obtienen si se minimiza la desviación al cuadrado. medir_distancia_ml &lt;- function(modelo, datos) { diferencia &lt;- datos$y - (modelo[1] + modelo[2] * datos$x) sqrt(mean(diferencia^2)) } beta &lt;- optim(c(0, 0), medir_distancia_ml, datos = sim1a) beta$par ## [1] 6.093167 1.476972 En la práctica no es recomendable usar optim() para ajustar un modelo, es mejor utilizar implementaciones ya existentes como rlm() y lqs() que son parte del paquete MASS. La justificación es que estas implementaciones permiten ajustar modelos robustos sin los múltiples problemas de carácter numérico que pueden surgir de manera condicional a los datos al momento de usar optim(). Un desafío al realizar optimización numérica es que únicamente garantiza encontrar un óptimo local. ¿Qué problema se presenta al optimizar un modelo de tres parámetros como el que se presenta a continuación? modelo3 &lt;- function(a, datos) { a[1] + datos$x * a[2] + a[3] } Solución El problema es que dados los valores a[1] = a1 y a[3] = a3, cualquier otra combinación de a[1] y a[3] tal que a[1] + a[3] == (a1 + a3) tendrá el mismo ajuste. medir_distancia_3_ml &lt;- function(a, datos) { diferencia &lt;- datos$y - modelo3(a, datos) sqrt(mean(diferencia^2)) } Dependiendo de los valores inciales se van a obtener distintos valores óptimos. beta_000 &lt;- optim(c(0, 0, 0), medir_distancia_3_ml, datos = sim1a) beta_000$par ## [1] -3.600968 1.476818 9.695246 beta_001 &lt;- optim(c(0, 0, 1), medir_distancia_3_ml, datos = sim1a) beta_001$par ## [1] -11.78327 1.47677 17.87682 beta_005 &lt;- optim(c(0, 0, 5), medir_distancia_3_ml, datos = sim1a) beta_005$par ## [1] 1.401055 1.476941 4.691592 Si seguimos alterando los valores inciales no es muy difícil concluir que existen infinitos valores óptimos para este modelo. 18.3 Visualizando modelos 18.3.1 Ejercicios En lugar de usar lm() para ajustar una línea recta, puedes usar loess() para ajustar una curva suave. Repite el proceso de ajustar el modelo, generar la cuadrícula, predicciones y visualización con sim1 usando loess() en vez de lm(). ¿Cómo se compara el resultado a geom_smooth(). Solución Usando add_predictions() y add_residuals() se pueden agregar las predicciones y los residuos de la regresión loess a los datos sim1a. sim1_loess &lt;- loess(y ~ x, data = sim1a) sim1_lm &lt;- lm(y ~ x, data = sim1a) grid_loess &lt;- sim1a %&gt;% add_predictions(sim1_loess) sim1a &lt;- sim1a %&gt;% add_residuals(sim1_lm) %&gt;% add_predictions(sim1_lm) %&gt;% add_residuals(sim1_loess, var = &quot;resid_loess&quot;) %&gt;% add_predictions(sim1_loess, var = &quot;pred_loess&quot;) Ahora procedemos a graficar las predicciones. La regresión loess genera un ajuste no lineal a partir de los datos. plot_sim1_loess &lt;- ggplot(sim1, aes(x = x, y = y)) + geom_point() + geom_line(aes(x = x, y = pred), data = grid_loess, colour = &quot;red&quot;) plot_sim1_loess Las predicciones del modelo loess son las mismas que entrega el método por defecto de geom_smooth() ya que este usa loess() y entrega un mensaje al respecto. plot_sim1_loess + geom_smooth(method = &quot;loess&quot;, colour = &quot;blue&quot;, se = FALSE, alpha = 0.20) Podemos graficar los residuos de loess (en rojo) y compararlos con los del modelo lineal (en negro). En general, el modelo loess tiene un menor residuo dada la muestra (fuera de la muestra no se asegura este comportamiento y no hemos considerado la incertidumbre de la estimación). ggplot(sim1a, aes(x = x)) + geom_ref_line(h = 0) + geom_point(aes(y = resid)) + geom_point(aes(y = resid_loess), colour = &quot;red&quot;) add_predictions() está pareada con gather_predictions() y spread_predictions(). ¿Cómo difieren estas tres funciones? Solución Las funciones gather_predictions() y spread_predictions() permiten incluir simultáneamente las predicciones de múltiples modelos. Por ejemplo, se puede incluir sim1_mod. sim1_mod &lt;- lm(y ~ x, data = sim1) grid &lt;- sim1 %&gt;% data_grid(x) La función add_predictions() permite incluir un modelo a la vez. Para agregar dos modelos se debe encadenar con el operador %&gt;%. grid %&gt;% add_predictions(sim1_mod, var = &quot;pred_lm&quot;) %&gt;% add_predictions(sim1_loess, var = &quot;pred_loess&quot;) ## # A tibble: 10 x 3 ## x pred_lm pred_loess ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 6.27 8.49 ## 2 2 8.32 8.89 ## 3 3 10.4 9.90 ## 4 4 12.4 11.5 ## 5 5 14.5 13.6 ## 6 6 16.5 15.2 ## 7 7 18.6 16.7 ## 8 8 20.6 18.2 ## 9 9 22.7 19.5 ## 10 10 24.7 20.4 La función gather_predictions() incorpora predicciones de múltiples modelos por medio de agrupar los resultados e incluir una columna con el nombre del modelo. grid %&gt;% gather_predictions(sim1_mod, sim1_loess) ## # A tibble: 20 x 3 ## model x pred ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 sim1_mod 1 6.27 ## 2 sim1_mod 2 8.32 ## 3 sim1_mod 3 10.4 ## 4 sim1_mod 4 12.4 ## 5 sim1_mod 5 14.5 ## 6 sim1_mod 6 16.5 ## 7 sim1_mod 7 18.6 ## 8 sim1_mod 8 20.6 ## 9 sim1_mod 9 22.7 ## 10 sim1_mod 10 24.7 ## 11 sim1_loess 1 8.49 ## 12 sim1_loess 2 8.89 ## 13 sim1_loess 3 9.90 ## 14 sim1_loess 4 11.5 ## 15 sim1_loess 5 13.6 ## 16 sim1_loess 6 15.2 ## 17 sim1_loess 7 16.7 ## 18 sim1_loess 8 18.2 ## 19 sim1_loess 9 19.5 ## 20 sim1_loess 10 20.4 La función spread_predictions() incorpora predicciones de múltiples modelos agregando múltiples columnas (de acuerdo al nombre de cada modelo) que contienen las predicciones respectivas. grid %&gt;% spread_predictions(sim1_mod, sim1_loess) ## # A tibble: 10 x 3 ## x sim1_mod sim1_loess ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 6.27 8.49 ## 2 2 8.32 8.89 ## 3 3 10.4 9.90 ## 4 4 12.4 11.5 ## 5 5 14.5 13.6 ## 6 6 16.5 15.2 ## 7 7 18.6 16.7 ## 8 8 20.6 18.2 ## 9 9 22.7 19.5 ## 10 10 24.7 20.4 La función spread_predictions() es similar a correr add_predictions() para cada modelo que se quiere incorporar y es equivalente a correr spread() luego de gather_predictions(). grid %&gt;% gather_predictions(sim1_mod, sim1_loess) %&gt;% spread(model, pred) ## # A tibble: 10 x 3 ## x sim1_loess sim1_mod ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 8.49 6.27 ## 2 2 8.89 8.32 ## 3 3 9.90 10.4 ## 4 4 11.5 12.4 ## 5 5 13.6 14.5 ## 6 6 15.2 16.5 ## 7 7 16.7 18.6 ## 8 8 18.2 20.6 ## 9 9 19.5 22.7 ## 10 10 20.4 24.7 ¿Qué hace geom_ref_line()? ¿De qué paquete proviene? ¿Por qué es útil e importante incluir una línea de referencia en los gráficos que muestran residuos? Solución La geometría geom_ref_line() agrega una línea de referencia al gráfico. Es el equivalente a usar geom_hline() o geom_vline() con las opciones por defecto y que nos sirven para visualizar modelos. Agregar una línea de referencia en torno a cero para los residuos es importante ya que un buen modelo, por lo general, tiene residuos centrados en torno a cero. Otras características relevantes son que los errores deben tener idéntica varianza y no estar correlacionados entre si. La línea de referencia en torno a cero permite evaluar visualmente estas características. ¿Por qué quisieras mirar un polígono de frecuencias con los residuos absolutos? ¿Cuáles son las ventajas y desventajas de los residuos crudos? Solución Mostrar los valores absolutos de los residuos facilita ver la magnitud del error. El modelo lineal asume que los residuos tienen media cero y usar los valores absolutos de los residuos permite ver lo que ocurre cuando los errores de signos opuestos no se cancelan mutuamente. sim1_mod &lt;- lm(y ~ x, data = sim1a) sim1 &lt;- sim1 %&gt;% add_residuals(sim1_mod) ggplot(sim1a, aes(x = abs(resid))) + geom_freqpoly(binwidth = 0.5) El inconveniente que aparece visualmente es que se pierde toda información respecto de los signos de los residuos. Por lo tanto, el polígono de frecuencias no distingue si acaso el modelo sobre-estima o sub-estima de manera consistente. 18.4 Fórmulas y familias de modelos 18.4.1 Ejercicios ¿Qué pasa si repites el análisis de sim2 usando un modelo sin intercepto? ¿Qué ocurre con la ecuación del modelo? ¿Qué ocurre con las predicciones? Solución Para estimar el modelo sin intercepto agregamos -1 o +0 al lado derecho de la fórmula. mod2a &lt;- lm(y ~ x - 1, data = sim2) mod2 &lt;- lm(y ~ x, data = sim2) Las predicciones son las mismas en el caso con o sin intercepto: grid &lt;- sim2 %&gt;% data_grid(x) %&gt;% spread_predictions(mod2, mod2a) grid ## # A tibble: 4 x 3 ## x mod2 mod2a ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a 1.15 1.15 ## 2 b 8.12 8.12 ## 3 c 6.13 6.13 ## 4 d 1.91 1.91 Usa model_matrix() para explorar las ecuaciones generadas por los modelos ajustados a sim3 y sim4. ¿Por qué * es un atajo para la interacción? Solución El caso x1 * x2 cuando x2 es una variable categórica produce las variables binarias x2b, x2c y x2d y las variables continuas x1:x2b, x1:x2c y x1:x2d que son el producto de x1 y x2*. x3 &lt;- model_matrix(y ~ x1 * x2, data = sim3) x3 ## # A tibble: 120 x 8 ## `(Intercept)` x1 x2b x2c x2d `x1:x2b` `x1:x2c` `x1:x2d` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 0 0 0 0 0 0 ## 2 1 1 0 0 0 0 0 0 ## 3 1 1 0 0 0 0 0 0 ## 4 1 1 1 0 0 1 0 0 ## 5 1 1 1 0 0 1 0 0 ## 6 1 1 1 0 0 1 0 0 ## 7 1 1 0 1 0 0 1 0 ## 8 1 1 0 1 0 0 1 0 ## 9 1 1 0 1 0 0 1 0 ## 10 1 1 0 0 1 0 0 1 ## # … with 110 more rows Podemos confirmar que las variables x1:x2b son el producto de x1 y x2b. all(x3[[&quot;x1:x2b&quot;]] == (x3[[&quot;x1&quot;]] * x3[[&quot;x2b&quot;]])) ## [1] TRUE Es similar para x1:x2c y x2c como para el caso de x1:x2d y x2d. all(x3[[&quot;x1:x2c&quot;]] == (x3[[&quot;x1&quot;]] * x3[[&quot;x2c&quot;]])) ## [1] TRUE all(x3[[&quot;x1:x2d&quot;]] == (x3[[&quot;x1&quot;]] * x3[[&quot;x2d&quot;]])) ## [1] TRUE Para x1 * x2 cuando x1 y x2 son continuas, model_matrix() creas las variables x1, x2 y x1:x2. x4 &lt;- model_matrix(y ~ x1 * x2, data = sim4) x4 ## # A tibble: 300 x 4 ## `(Intercept)` x1 x2 `x1:x2` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 -1 -1 1 ## 2 1 -1 -1 1 ## 3 1 -1 -1 1 ## 4 1 -1 -0.778 0.778 ## 5 1 -1 -0.778 0.778 ## 6 1 -1 -0.778 0.778 ## 7 1 -1 -0.556 0.556 ## 8 1 -1 -0.556 0.556 ## 9 1 -1 -0.556 0.556 ## 10 1 -1 -0.333 0.333 ## # … with 290 more rows Se puede confirmar que x1:x2 es el producto de x1 y x2. all(x4[[&quot;x1&quot;]] * x4[[&quot;x2&quot;]] == x4[[&quot;x1:x2&quot;]]) ## [1] TRUE Usando los principios básicos, convierte las fórmulas de los siguientes modelos en funciones. (Sugerencia: comienza por convertir las variables categóricas en ceros y unos.) mod1 &lt;- lm(y ~ x1 + x2, data = sim3) mod2 &lt;- lm(y ~ x1 * x2, data = sim3) Solución El lado derecho de las fórmulas se encarga de generar una matriz de diseño a partir de las columnas x1 y x2, lo que se ve reflejado en model_matrix(). Veamos los niveles de x2, que por ser una variable categórica es la más compleja de llevar a la matriz de diseño. x1 permanece inalterada. levels(sim3$x2) ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; Para el caso ~ x1 + x2 lo que haremos es considerar “a” como el nivel de referencia, por lo que se omite, y luego generamos nuevas columnas para los niveles “b”, “c” y “d”. model_matrix_mod1 &lt;- function(.data) { mutate(.data, x2b = as.numeric(x2 == &quot;b&quot;), x2c = as.numeric(x2 == &quot;c&quot;), x2d = as.numeric(x2 == &quot;d&quot;), `(Intercept)` = 1 ) %&gt;% select(`(Intercept)`, x1, x2b, x2c, x2d) } model_matrix_mod1(sim3) ## # A tibble: 120 x 5 ## `(Intercept)` x1 x2b x2c x2d ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 0 0 0 ## 2 1 1 0 0 0 ## 3 1 1 0 0 0 ## 4 1 1 1 0 0 ## 5 1 1 1 0 0 ## 6 1 1 1 0 0 ## 7 1 1 0 1 0 ## 8 1 1 0 1 0 ## 9 1 1 0 1 0 ## 10 1 1 0 0 1 ## # … with 110 more rows Es posible crear función para ~ x1 + x2 que no depende de los niveles específicos de x2. model_matrix_mod1b &lt;- function(.data) { # niveles de x2 lvls &lt;- levels(.data$x2) # borramos el primer nivel (es de referencia) # asumimos que hay al menos dos niveles lvls &lt;- lvls[2:length(lvls)] # creamos una variable binaria para cada nivel de x2 for (lvl in lvls) { varname &lt;- str_c(&quot;x2&quot;, lvl) .data[[varname]] &lt;- as.numeric(.data$x2 == lvl) } # generamos una lista de las variables que se mantienen x2_variables &lt;- str_c(&quot;x2&quot;, lvls) # agregamos el intercepto .data[[&quot;(Intercept)&quot;]] &lt;- 1 # mantenemos las variables binarias x1 y x2 select(.data, `(Intercept)`, x1, one_of(x2_variables)) } model_matrix_mod1b(sim3) ## # A tibble: 120 x 5 ## `(Intercept)` x1 x2b x2c x2d ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 0 0 0 ## 2 1 1 0 0 0 ## 3 1 1 0 0 0 ## 4 1 1 1 0 0 ## 5 1 1 1 0 0 ## 6 1 1 1 0 0 ## 7 1 1 0 1 0 ## 8 1 1 0 1 0 ## 9 1 1 0 1 0 ## 10 1 1 0 0 1 ## # … with 110 more rows Para el caso ~ x1 * x2 hay que tener en cuenta que debemos generar una columna por cada nivel de x2, sin contar el nivel de referencia que interactúa con x1. model_matrix_mod2 &lt;- function(.data) { mutate(.data, `(Intercept)` = 1, x2b = as.numeric(x2 == &quot;b&quot;), x2c = as.numeric(x2 == &quot;c&quot;), x2d = as.numeric(x2 == &quot;d&quot;), `x1:x2b` = x1 * x2b, `x1:x2c` = x1 * x2c, `x1:x2d` = x1 * x2d ) %&gt;% select(`(Intercept)`, x1, x2b, x2c, x2d, `x1:x2b`, `x1:x2c`, `x1:x2d`) } model_matrix_mod2(sim3) ## # A tibble: 120 x 8 ## `(Intercept)` x1 x2b x2c x2d `x1:x2b` `x1:x2c` `x1:x2d` ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 0 0 0 0 0 0 ## 2 1 1 0 0 0 0 0 0 ## 3 1 1 0 0 0 0 0 0 ## 4 1 1 1 0 0 1 0 0 ## 5 1 1 1 0 0 1 0 0 ## 6 1 1 1 0 0 1 0 0 ## 7 1 1 0 1 0 0 1 0 ## 8 1 1 0 1 0 0 1 0 ## 9 1 1 0 1 0 0 1 0 ## 10 1 1 0 0 1 0 0 1 ## # … with 110 more rows Es posible crear una función para ~ x1 * x2 que no depende de los niveles específicos de x2. model_matrix_mod2b &lt;- function(.data) { # partimos de la base del modelo x1 + x2 out &lt;- model_matrix_mod1b(.data) # tomamos las columnas que contienen &quot;x2&quot; x2cols &lt;- str_subset(colnames(out), &quot;^x2&quot;) # creamos las variables de interacción for (varname in x2cols) { newvar &lt;- str_c(&quot;x1:&quot;, varname) out[[newvar]] &lt;- out$x1 * out[[varname]] } out } model_matrix_mod2b(sim3) ## # A tibble: 120 x 8 ## `(Intercept)` x1 x2b x2c x2d `x1:x2b` `x1:x2c` `x1:x2d` ## &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 0 0 0 0 0 0 ## 2 1 1 0 0 0 0 0 0 ## 3 1 1 0 0 0 0 0 0 ## 4 1 1 1 0 0 1 0 0 ## 5 1 1 1 0 0 1 0 0 ## 6 1 1 1 0 0 1 0 0 ## 7 1 1 0 1 0 0 1 0 ## 8 1 1 0 1 0 0 1 0 ## 9 1 1 0 1 0 0 1 0 ## 10 1 1 0 0 1 0 0 1 ## # … with 110 more rows Estas funciones se podrían generalizar para los casos en que x1 y x2 pueden ser de tipo numérico o categórico. Si seguimos generalizando acabaremos reescribiendo la función matrix_model(). Para sim4, ¿Es mejor mod1 o mod2? Yo creo que mod2 es ligeramente mejor removiendo las tendencias, pero es bastante sutil. ¿Puedes generar un gráfico que de sustento a esta hipótesis? Solución Estimamos los modelos mod1 y mod2 a partir de sim4, mod1 &lt;- lm(y ~ x1 + x2, data = sim4) mod2 &lt;- lm(y ~ x1 * x2, data = sim4) Luego agregamos los residuos a los datos de sim4. sim4_mods &lt;- gather_residuals(sim4, mod1, mod2) Ahora podemos generar un gráfico de frecuencias de los residuos y los valores absolutos de estos. ggplot(sim4_mods, aes(x = resid, colour = model)) + geom_freqpoly(binwidth = 0.5) + geom_rug() ggplot(sim4_mods, aes(x = abs(resid), colour = model)) + geom_freqpoly(binwidth = 0.5) + geom_rug() Esto no muestra una gran diferencia. Sin embargo, mod2 parece tener menos residuos en las colas de la distribución entre 2,5 y 5, aunque los residuos más extremos son los de este modelo. Podemos verificar lo anterior calculando la desviación estándar de los residuos para cada modelo. sim4_mods %&gt;% group_by(model) %&gt;% summarise(resid = sd(resid)) ## # A tibble: 2 x 2 ## model resid ## &lt;chr&gt; &lt;dbl&gt; ## 1 mod1 2.10 ## 2 mod2 2.07 La desviación estándar de los residuos de mod2 es menor que la de mod1. "]
]
